{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATAINGESTION-TRAINING STEPS:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "config/config.yaml , params.yaml , dvc.yaml ------ tests/unit/integration tests\n",
    "\n",
    "src/deepClassifier/-config-entity-constants-utils\n",
    "\n",
    "dataingestion\n",
    "preparingmode               all three goes to Training --- Best Model Selector\n",
    "prepare Callbacks \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants-init- has \n",
    "CONFIG_FILE_PATH,PARAMS_FILE_PATH = paths of both these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAGE1:DATA-INGESTION:\n",
    "Config.yaml: data_ingestion: this is key for neseted key-value pair of \n",
    "root_dir:,source_url:,local_data_file:,unzip_dir:\n",
    "\n",
    "## named tuple creation:by class method\n",
    "1.DataIngestionConfig: class : has class-variables:root_dir,source_URL,local_data_file,unzip_dir\n",
    "2.ConfigurationManager class :\n",
    "   1. init taken config_file_path and param_file_path.\n",
    "   2. create root directory /artifacts from utility we imported create_directories class\n",
    "   3.get_data_ingestion_config() : class : created root directory for this point and merges config.yaml values with named tuple keys\n",
    "3. COMPONENT: \n",
    "    DataIngestion:\n",
    "        1. init has config:DataIngestionConfig\n",
    "        2. download_file(): function : if datafile doesnot exists in the system then only do the download, with urllib.request lib retrieved the data\n",
    "        3. unzip_and_clean(): function : reading the zip file and cleaning the files such as other than jpeg format and 0kb size file will be removed for that filename.namelist() : function : helps to find names of images and also used hidden method _get_updated_list_of_files() : function : to remove those unwanted files, _preprocess(): hidden method function : size is checked and removed\n",
    "\n",
    "        4. _get_updated_list_of_files() : function : here given conditions: endswith jpeg and names of file is cat or dog then only select those files.\n",
    "\n",
    "        5. _preprocess() : function : to remove 0kb size file.\n",
    "4. pipeline created : by taking ConfigurationManager, take all functions in component and ConfigManager.\n",
    "    get_data_ingestion_config(),download_file(),unzip_and_clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAGE-2: PrepareBaseModelConfig:\n",
    "\n",
    "config.yaml: has prepare_base_model key with key-value pairs of\n",
    "root_dir: artifact dir,base_model_path:model.h5,updated_base_model_path:transfer learning model.\n",
    "\n",
    "# named tuple by dataclass decorator method\n",
    "1. PrepareBaseModelConfig: class : \n",
    "    has type casting of root_dir:, base_model_path:,updated_base_model_path:, params_image_size:,params_classes:,params_learning_rate:,params_include_top:,params_weights:\n",
    "2. ConfigurationManager class :\n",
    "    1. get_prepare_base_model_config(): function : creating directory for this stage and get config details from data class method,provide values by joining with the  config.yaml.\n",
    "3. Component:\n",
    "    PrepareBaseModel(): class : has \n",
    "    1. init has config: named tuple PrepareBaseModelConfig\n",
    "    # visual-geometric-group\n",
    "    2. get_base_model() : function : has model object of tf.keras.applications.vgg16.VGG16(input_shape,weights,include_top)\n",
    "    # Include top =True cnn+ann, false = only cnn\n",
    "    # params.yaml \n",
    "    base model path is defined and used in save_model() function \n",
    "        @staticmethod\n",
    "    3. _prepare_full_model(): if freeze_all is selected then with forloop make all layers untrainable, else use freeze till option\n",
    "    then apply flatten operation by \n",
    "    flatten_in= tf.keras.layers.Flatten()(model.output)\n",
    "    prediction layer added = tf.keras.layers.Dense(units=classes,activation='softmax)(flatten_in)\n",
    "    # (flatten_in) this is input for prediction layer \n",
    "    full_model = tf.keras.models.Model(inputs=model.input,output = prediction)\n",
    "    full_modile.compile()\n",
    "    4. update_base_model(): function : full_model is defined that has attributes basemodel, classes,freeze_all :freezing all layers, freeze_till: till what layer :given None ,learning_rate\n",
    "    self.save_model(path,model=self.full_model)\n",
    "       @staticmethod\n",
    "    5. save_model(): function : it takes model, path as input variables and save it\n",
    "4. pipeline :\n",
    "     has configurationManager function get_prepare_base_model_config() and component functions  get_base_model(),update_base_model(),save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMS.yaml\n",
    "1.AUGUMENTATION: TRUE (if data is not sufficient go with this this multiply same data by changing minute things in that.)\n",
    "2. IMAGE_SIZE : [224,224,3] vgg16 model takes input as this size\n",
    "3. INCLUDE_TOP : FALSE we are using only CNN layer here.\n",
    "4. EPOCHS:1 only one cycle we are running as we are doing testing \n",
    "5. CLASSES :2  cat/dog are 2 classes\n",
    "6. WEIGHTS: imagenet ( imagenet is a dataset , in competition,it has 1000 no of classes(animals) it has wide variety of trained weights)\n",
    "7. LEARNING_RATE : 0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stage:3 -Prepare callback\n",
    "\n",
    "config.yaml : prepare_callbacks: root_dir,\n",
    "tensorboard_root_log_dir,checkpoint_model_file_path -> key-value pairs.\n",
    "\n",
    "1. dataclass method : namedtuple:\n",
    "    PrepareCallbackConfig: class : has rootdir,tensorboard_root_log_dir,checkpoint_model_file_path\n",
    "2. ConfigManager(): class: linking config.yaml and dataclass named tuple with the help of PrepareCallbacksConfig() function.created folders for tensorboard_log_dir,checkpoint_dir.\n",
    "3. Component:\n",
    "    PrepareCallback(): class : has \n",
    "     1. init takes PrepareCallbacksConfig function from configurationManager.\n",
    "     2. get_to_ckpt_callbacks() function that returns hidden functions i.e. _create_tb_callbacks() , _create_ckpt_callbacks().\n",
    "     3. @property\n",
    "        def _create_tb_callbacks() : function : dir details with time stamp, it has log files we can use for visualisation later\n",
    "     4. @property\n",
    "        _create_ckpt_callbacks() : it saves best weights based on best loss , saves in model.h5 .\n",
    "\n",
    "4. pipeline:\n",
    "    ConfigurationManager(), Prepare_Callbacks_Config()->namedtuple,                 PrepareCallback.get_to_ckpt_callbacks(),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# callbacks:\n",
    "1st epoch, 2nd epoch , 3rd epoch etc \n",
    "if given 1000 epochs system may get crash to memorise all,\n",
    "callback calls a func and come back and that func saves the weights generated in that epoch and if powerloss happens we can continue from the last epoch because of the callback\n",
    "early stopping is done based on callback info if same loss in many epoch it will stop training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stage:04 -Training\n",
    "config.yaml: root_dir->path, trained_model_path->path\n",
    "1.dataclass: namedtuple:\n",
    "    root_dir->path, trained_model_path->path,updated_base_model_path,trainig_data->path,\n",
    "    params_epochs,params_batch_size,param_is_augumentation,params_image_size\n",
    "\n",
    "\n",
    "2.ConfigurationManager:\n",
    "    1.get_training_config():func: connects various stages path,config.yaml and params.yaml and dataclass namedtuple.\n",
    "3. component:\n",
    "    1. Class Training: init has Training_config\n",
    "    2. get_base_model():func: gives base model path\n",
    "    3. train_valid_generator():func: does data augumentation, by taking params \n",
    "        it has datagenerator_kwargs= dict(),dataflow_kwargs=dict(), \n",
    "        valid_datagenerator = keras.preprocessing.image.ImageDataGenerator(**datagenerator_kwargs)\n",
    "        self.valid_generator= valid_generator.flow_from_directory(**dataflow_kwargs,dir,subset,shuffle) similarly create self.train_generator\n",
    "        check for augumentation : parameters are defined such as rotation,flip,shear_range,width_shift,height_shift\n",
    "    4. train:func: step_per_epoch,validation_steps,\n",
    "    self.model.fit(self.train_generator,epochs,steps_per_epoch,validation_steps,validation_data,callbacks), \n",
    "    5. def save_model():func: saves the model.takes, path and model are inputs.\n",
    "        \n",
    "4. pipeline:\n",
    "    ConfigurationManager(), prepare_callbacks_config=config.prepare_callback_config, PrepareCallback(config=preprae_callbacks_config), PrepareCallback.get_to_ckpt_callbacks(),\n",
    "    training_config, training.train_valid_generator(), callbacks=callbacks_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interpolation: \n",
    "    a line has 1,2,3,4,5 if we want points b/w 1,2 with interpolation we get it.used for stretching or shrinking an image. 2 4  --->  6*6 matrix b/w 1-5\n",
    "                                      1 5\n",
    "# data_generator:\n",
    " it doesnot increases images number, but while training it creates new features to improve training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling one func as input to another function:\n",
    "def example(x,**kwargs):\n",
    "    print(locals())\n",
    "extra = dict(y=4,z=55)\n",
    "example(x=3,**extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stage:05:Evaluation\n",
    "\n",
    "1. Dataclass: class  EvaluationConfig: path_of_model,training_data,params_image_size,parms_batchsize\n",
    "2. ConfigurationManager: \n",
    "    1. get_validation_config():func: connects pathsfrom dataclass\n",
    "3. component:\n",
    "    Evaluation: class:\n",
    "    1. _valid_generator()->trainingstage,\n",
    "    2. load_model()\n",
    "    3. validation() : self.score=model.evaluate(self.valid_generator)\n",
    "    4. def save_score(): scores from validation func is saved in json format by calling save_json function from utils-common.py\n",
    "4. pipeline: ConfigurationManager().get_validation_config(),Evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bb23044150999111d4eec4be9a4ddf2c3d3773860edfcf74ae8f45205dadf64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
